{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An introduction to solving biological problems with Python\n",
    "\n",
    "## Session 2.3: Files\n",
    "\n",
    "- [Using files](#Using-files)\n",
    "- [Data formats](#Data-formats)\n",
    "- [Python file library](#Python-file-library)\n",
    "- [Reading command line arguments](#Reading-command-line-arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data input and output (I/O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, all that data we have been working with has been written by us into our scripts, and the results of out computation has just been displayed in the terminal output. In the real world data will be supplied by the user of our programs (who may be you!) by some means, and we will often want to save the results of some analysis somewhere more permanent than just printing it to the screen. In this session we cover 2 widely used ways of reading data into our programs, via the command line and by reading files from dish, we also discuss writing out data to files. \n",
    "\n",
    "There are, of course, many other ways of accessing data, such as querying a database or retrieving data from a network such as the internet. We don't cover these here, but python has excellent support for interacting with databases and networks either in the standard library or using external modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequently the data we want to operate on or analyse will be stored in files, so in our programs we need to be able to open files, read through them (perhaps all at once, perhaps not), and then close them. \n",
    "\n",
    "We will also frequently want to be able to print output to files rather than always printing out results to the terminal.\n",
    "\n",
    "Python supports all of these modes of operations on files, and provides a number of useful functions and syntax to make dealing with files straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To open a file, python provides the `open` function, which takes a filename as its first argument and returns a _file object_ which is python's internal representation of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"data/datafile.txt\"\n",
    "fileObj = open( path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`open` takes an optional second argument specifying the _mode_ in which the file is opened, either for reading, writing or appending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "open( \"data/myfile.txt\", \"r\" ) # open for reading, default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "open( \"data/myfile.txt\", \"w\" ) # open for writing (existing files will be overwritten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "open( \"data/myfile.txt\", \"a\" ) # open for appending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Mode modifiers__\n",
    "\n",
    "These mode strings can include some extra modifier characters that deal with issues in dealing with files across multiple platforms.\n",
    "\n",
    "`b`: binary mode, e.g. `\"rb\"`. No translation for end-of-line chanracters to platform specific setting value.\n",
    "\n",
    "`U`: universal new line mode, e.g. `\"rU\"`. Present end-of-line as `\"\\n\"` no matter where the file was written."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To close a file once you finished with it, you can call the `.close` method on a file object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have opened a file for reading, file objects provide a number of methods for accessing the data in a file. The simplest of these is the `.read` method that reads the entire contents of the file into a string variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileObj = open( \"data/datafile.txt\" )\n",
    "print fileObj.read() # everything\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if this means the entire file will be read into memory, if you are operating on a large file and don't actually need all the data at the same time this is rather inefficient.\n",
    "\n",
    "Frequently, we just need to operate on individuals lines of the file, and you can use the `.readline` method to read a line from a file and return it as a python string.\n",
    "\n",
    "File objects internally keep track of your current location in a file, so to get following lines from the file you can call this method multiple times.\n",
    "\n",
    "It is important to note that the string representing each line will have a trailing newline `\"\\n\"` character, which you may want to remove with the `.rstrip` string method.\n",
    "\n",
    "Once the end of the file is reached, `.readline` will return an empty string `''`. This is different from an apparently empty line in a file, as even an empty line will contain a newline character. Recall that the empty string is considered as `False` in python, so you can readily check for this condition with an `if` statement etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one line at a time\n",
    "fileObj = open( \"data/datafile.txt\" )\n",
    "print \"1st line: %r\" % fileObj.readline()\n",
    "print \"2nd line: %r\" % fileObj.readline()\n",
    "print \"3rd line: %r\" % fileObj.readline()\n",
    "print \"4th line: %r\" % fileObj.readline()\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read in all lines from a file as a list of strings containing the data from each line, use the `.readlines` method (though note that this will again read all data into memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# all lines\n",
    "fileObj = open( \"data/datafile.txt\" )\n",
    "\n",
    "lines = fileObj.readlines()\n",
    "\n",
    "print \"The file has\", len(lines), \"lines\"\n",
    "\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping over the lines in a file is a very common operation and python lets you iterate over a file using a `for` loop just as if it were an array of strings. This does not read all data into memory at once, and so is much more efficient that reading the file with `.readlines` and then looping over the resulting list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# as an iterable\n",
    "fileObj = open( \"data/datafile.txt\" )\n",
    "\n",
    "for line in fileObj:\n",
    "    print line.rstrip().upper()\n",
    "\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The with statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important that files are closed when they are no longer required, but writing ``fileObj.close()`` is tedious (and more importantly, easy to forget). An alternative syntax is to open the files within a ``with`` statement, in which case the file will automatically be closed at the end of the `with` block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fileObj will be closed when leaving the block\n",
    "with open( \"data/datafile.txt\" ) as fileObj:\n",
    "    for ( i, line ) in enumerate( fileObj, start = 1 ):\n",
    "        print \"%s: %r\" % ( i, line )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing to files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a file has been opened for writing, you can use the `.write` method on a file object to write data to the file.\n",
    "\n",
    "The argument to the `.write` method must be a string, so if you want to write out numerical data to a file you will have to convert it to a string somehow beforehand.\n",
    "\n",
    "Remember to include a newline character to separate lines of your output, unlike the `print` statement, `.write` does not include this by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "read_counts = {\n",
    "    'BRCA2': 43234,\n",
    "    'FOXP2': 3245,\n",
    "    'SORT1': 343792\n",
    "}\n",
    "\n",
    "with open( \"out.txt\", \"w\" ) as output:\n",
    "    output.write(\"GENE\\tREAD_COUNT\\n\")\n",
    "\n",
    "    for gene in read_counts:\n",
    "        line = \"\\t\".join( [ gene, str(read_counts[gene]) ] )\n",
    "        output.write(line+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat out.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be cautious when opening a file for writing, as python will happily let you overwrite any existing data in the file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4.2] Exercises\n",
    "\n",
    "1. Write a script that writes the values of a list of numbers to a file, with each number on a seperate line.\n",
    "\n",
    "2. Write a script that takes the name of a file containing many lines of nucleotide sequence as a command line argument and opens the file for reading (checking that the filename supplied does exist). For each line in the file, print out the line number and the length of the corresponding line (There is an example file <a href=\"http://www.ebi.ac.uk/~grsr/perl/dna.txt\">here</a> or in `data/dna.txt` from the course materials ).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bioinformaticians love creating endless new file formats for their data, but there are a number of very common standard formats that it is good to get used to parsing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delimited:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X 169008682 1 111267453 1.0976\n",
    "2 8265484 5 69763543 4.9825\n",
    "MT 10924 MT 81934 7.2357\n",
    "3 127 8 10908776 1.2509"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading delimited files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the various string manipulation techniques covered earlier to process delimited files in a fairly straightforward way. Here we loop through a file with columns delimited by spaces, reading the data for each row into a list, and storing each of these lists into a main results list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat data/mydata.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "with open(\"data/mydata.txt\", \"r\") as data:\n",
    "    header = data.readline()\n",
    "    for line in data:\n",
    "        line = line.strip()\n",
    "        results.append(line.split(\" \"))\n",
    "        \n",
    "print results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we show a slightly more complicated example where we are reading the results into a more convenient data structure, a list of dictionaries with the dictionary keys corresponding to the column headers and the values to the values from each line. We also convert the columns to an appropriate type as we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "with open(\"data/mydata.txt\", \"r\") as data:\n",
    "    header = data.readline()\n",
    "    for line in data:\n",
    "        idx, org, score = line.strip().split(\" \")\n",
    "        row = {'index': int(idx), 'organism': org, 'score': float(score)}\n",
    "        results.append(row)\n",
    "        \n",
    "print results\n",
    "print 'Score of first row:', results[0]['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing delimited files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing out a delimited file is also straightforward using the `join` method, or possibly using format strings. Here, as an example we will recreate our original file from above, but this time we will delimit the columns with a comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('data/mydata.csv', 'w') as output:\n",
    "    # write a header, using the keys from the first dictionary\n",
    "    header = \",\".join(results[0].keys())\n",
    "    output.write(header + \"\\n\")\n",
    "    for row in results:\n",
    "        vals = [str(v) for v in row.values()]\n",
    "        row_line = \",\".join(vals)\n",
    "        output.write(row_line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat data/mydata.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is actually a module in the standard library called `csv` which can also be used to read and write delimited files. There is some example code reading this same file using this library towards the end of this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the `csv` module to read and write delimited files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open( \"data/mydata.txt\", \"rb\" ) as f:\n",
    "    reader = csv.reader( f, delimiter = \" \" ) # delimiter defaults to \",\"\n",
    "    print list( reader )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read from list\n",
    "with open( \"data/mydata.txt\", \"rb\" ) as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "import csv\n",
    "reader = csv.reader( data, delimiter = \" \" )\n",
    "print list( reader )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in as dictionary\n",
    "results = []\n",
    "with open( \"data/mydata.txt\", \"rb\" ) as fileObj:\n",
    "    reader = csv.DictReader( fileObj, delimiter = \" \" ) # do no remove header\n",
    "    results.extend(list( reader ))\n",
    "    \n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write delimited files using the csv module from a list of list\n",
    "import csv\n",
    "\n",
    "mydata = [\n",
    "    ['1', 'Human', '1.076'], \n",
    "    ['2', 'Mouse', '1.202'], \n",
    "    ['3', 'Frog', '2.2362'], \n",
    "    ['4', 'Fly', '0.9853']\n",
    "]\n",
    "\n",
    "with open( \"csvdata.csv\", \"wb\" ) as fileObj:\n",
    "    writer = csv.writer( fileObj, delimiter='\\t' )\n",
    "    writer.writerow( [ \"Index\", \"Organism\", \"Score\" ] ) # write header\n",
    "\n",
    "    for record in mydata:\n",
    "        writer.writerow( record )\n",
    "\n",
    "with open( \"csvdata.csv\", \"rb\" ) as f:\n",
    "    print f.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write delimited files using the csv module from a list of dictionaries \n",
    "import csv\n",
    "\n",
    "mydata = [\n",
    "    {'Index': '1', 'Score': '1.076', 'Organism': 'Human'}, \n",
    "    {'Index': '2', 'Score': '1.202', 'Organism': 'Mouse'}, \n",
    "    {'Index': '3', 'Score': '2.2362', 'Organism': 'Frog'}, \n",
    "    {'Index': '4', 'Score': '0.9853', 'Organism': 'Fly'}\n",
    "]\n",
    "\n",
    "fieldnames = ['Index', 'Organism', 'Score']\n",
    "\n",
    "with open( \"csvdictdata.csv\", \"wb\" ) as fileObj:\n",
    "    writer = csv.DictWriter( fileObj, fieldnames, delimiter='\\t' )\n",
    "    writer.writeheader() # write header\n",
    "\n",
    "    for record in mydata:\n",
    "        writer.writerow( record )\n",
    "\n",
    "with open( \"csvdictdata.csv\", \"rb\" ) as f:\n",
    "    print f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python file library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`os`:\n",
    "\n",
    "- `chdir(path)` : change the current working directory to be path\n",
    "- `getcwd()` : return the current working directory\n",
    "- `listdir(path)` : returns a list of files/directories in the directory path\n",
    "- `mkdir(path)` : create the directory path\n",
    "- `rmdir(path)` : remove the directory path\n",
    "- `remove(path)` : remove the file path\n",
    "- `rename(src, dst)` : move the file/directory from src to dst\n",
    "\n",
    "`os.path`:\n",
    "\n",
    "- `exists(path)` : returns whether path exists\n",
    "- `isfile(path)` : returns whether path is a “regular” file (as opposed to a directory)\n",
    "- `isdir(path)` : returns whether path is a directory\n",
    "- `islink(path)` : returns whether path is a symbolic link\n",
    "- `join(*paths)` : joins the paths together into one long path\n",
    "- `dirname(path)` : returns directory containing the path\n",
    "- `basename(path)` : returns the path minus the dirname(path) in front\n",
    "- `split(path)` : returns (dirname(path), basename(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "os.path.join( \"home\", \"test\", \"mydoc.txt\" )\n",
    "# home/test/mydoc.txt - Unix\n",
    "# home\\test\\mydoc.txt - Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[4.3] Exercises__\n",
    "\n",
    "1. Write a program that reads in a tab delimited file with 4 columns: gene, chromosome, start and end coordinates. Compute the length of each gene and print the name of each gene and its corresponding length, seperated by a space, to a new file. You can find an example file <a href=\"http://www.ebi.ac.uk/~grsr/perl/genes.txt\">here</a>, or in ` data/genes.txt` directory of the course materials.\n",
    "\n",
    "2. Write a program that extends the search_gzip_file.py script in the scripts directory to use a file containing sample accession numbers and writes out a csv file containing the accession number and a boolean value whether it is in the *1000genomes* data or not. **Hint**: preprocess the *1000genomes* data into a data structure that allows quick membership tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "cat scripts/search_gzip_file.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python scripts/search_gzip_file.py SRS006837"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: Bonus exercise\n",
    "\n",
    "- use pandas to parse this file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading command line arguments\n",
    "\n",
    "A convenient way to supply arguments, such as data file names, algorithm parameters etc. to your script is via the command line used when you start your script running.\n",
    "\n",
    "All of the arguments supplied to your script are stored in an list which is available in the `sys` module we mentioned earlier, e.g. if you ran your script with a command line like:\n",
    "<br/>\n",
    "<tt>python script.py BRCA2 0.5</tt>\n",
    "<br/>\n",
    "<br/>\n",
    "Then the arguments `\"BRCA2\"` and `\"0.5\"` would be stored in `sys.argv` at the second and third positions, and the name of the script will be stored in first position in the list. You can access the elements of this list just like any other python list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat scripts/command.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python scripts/command.py 1 2 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all the command line arguments are strings (even if they look like numbers on the command line), so if you want to operate on them as numbers you will need to cast them to the appropriate numerical type first. If you try to cast something that cannot be interpreted as the relevant type then python will raise a `ValueError` exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "int(\"not a number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__[4.1] Exercises__\n",
    "\n",
    "1. Using the `sys` library, write a script that takes 2 integers from the command line, adds the 2 numbers and prints out the result. Your script will have to cast the string arguments to numbers, and it should check for a `ValueError` exception in case the user did not supply numbers. You should print out an error message in this case.\n",
    "2. Write a script that reads in a DNA sequence from the command line, and then prints out its length and GC percentage (using the code you wrote earlier on to compute the GC content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The `argparse` library__\n",
    "\n",
    "\n",
    "If you are developing a script and you want to read in standard unix command line options, i.e. those specified with a single or double hyphen such as `-h` or `--help`, there is a helpful library called `argparse` that you can use instead of directly operating on `sys.argv`. It also produces a helpful usage message. There are lots of options and settings, but here is a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat scripts/argparse_example.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python scripts/argparse_example.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "python scripts/argparse_example.py -s GCGCTGTGCCTGCAATGATCGT -l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
